{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/1xdj8pfj2cs3wjpc41g9qkj80000gn/T/ipykernel_1489/2430745749.py:8: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>IDStation</th>\n",
       "      <th>NameStation</th>\n",
       "      <th>Ammonia</th>\n",
       "      <th>Arsenic</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Benzo_a_pyrene</th>\n",
       "      <th>Cadmium</th>\n",
       "      <th>CO</th>\n",
       "      <th>Lead</th>\n",
       "      <th>...</th>\n",
       "      <th>IDStation.2</th>\n",
       "      <th>NameStation.1</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Wind_direction</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Relative_humidity</th>\n",
       "      <th>Global_radiation</th>\n",
       "      <th>Wind_speed_max</th>\n",
       "      <th>Wind_direction_max</th>\n",
       "      <th>Rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>677</td>\n",
       "      <td>Cremona Via Fatebenefratelli</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>677</td>\n",
       "      <td>Cremona Via Fatebenefratelli</td>\n",
       "      <td>0.483454</td>\n",
       "      <td>314.0</td>\n",
       "      <td>2.615278</td>\n",
       "      <td>93.738194</td>\n",
       "      <td>21.268056</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>681</td>\n",
       "      <td>Moggio</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Cassina Valsassina Moggio</td>\n",
       "      <td>0.300970</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.095833</td>\n",
       "      <td>74.055556</td>\n",
       "      <td>60.152778</td>\n",
       "      <td>1.939583</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01T00:00:00Z</td>\n",
       "      <td>703</td>\n",
       "      <td>Schivenoglia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.159091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>671</td>\n",
       "      <td>Mantova Tridolino</td>\n",
       "      <td>1.540787</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.761806</td>\n",
       "      <td>99.475694</td>\n",
       "      <td>14.163194</td>\n",
       "      <td>3.524306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02T00:00:00Z</td>\n",
       "      <td>677</td>\n",
       "      <td>Cremona Via Fatebenefratelli</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>677</td>\n",
       "      <td>Cremona Via Fatebenefratelli</td>\n",
       "      <td>1.788399</td>\n",
       "      <td>284.0</td>\n",
       "      <td>5.974306</td>\n",
       "      <td>70.609722</td>\n",
       "      <td>72.734028</td>\n",
       "      <td>4.377083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02T00:00:00Z</td>\n",
       "      <td>681</td>\n",
       "      <td>Moggio</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>Cassina Valsassina Moggio</td>\n",
       "      <td>0.613183</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.670139</td>\n",
       "      <td>39.194444</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>3.075000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date  IDStation                   NameStation  Ammonia  \\\n",
       "0  2018-01-01T00:00:00Z        677  Cremona Via Fatebenefratelli      6.2   \n",
       "1  2018-01-01T00:00:00Z        681                        Moggio      1.4   \n",
       "2  2018-01-01T00:00:00Z        703                  Schivenoglia      NaN   \n",
       "3  2018-01-02T00:00:00Z        677  Cremona Via Fatebenefratelli      1.8   \n",
       "4  2018-01-02T00:00:00Z        681                        Moggio      1.0   \n",
       "\n",
       "   Arsenic  Benzene  Benzo_a_pyrene  Cadmium        CO  Lead  ...  \\\n",
       "0      NaN      NaN             NaN      NaN  0.508333   NaN  ...   \n",
       "1      NaN      NaN             NaN      NaN       NaN   NaN  ...   \n",
       "2      NaN      1.0             NaN      NaN  1.159091   NaN  ...   \n",
       "3      NaN      NaN             NaN      NaN  0.375000   NaN  ...   \n",
       "4      NaN      NaN             NaN      NaN       NaN   NaN  ...   \n",
       "\n",
       "   IDStation.2                 NameStation.1  Wind_speed  Wind_direction  \\\n",
       "0          677  Cremona Via Fatebenefratelli    0.483454           314.0   \n",
       "1          111     Cassina Valsassina Moggio    0.300970            65.0   \n",
       "2          671             Mantova Tridolino    1.540787           288.0   \n",
       "3          677  Cremona Via Fatebenefratelli    1.788399           284.0   \n",
       "4          111     Cassina Valsassina Moggio    0.613183             9.0   \n",
       "\n",
       "   Temperature  Relative_humidity  Global_radiation  Wind_speed_max  \\\n",
       "0     2.615278          93.738194         21.268056        2.133333   \n",
       "1     2.095833          74.055556         60.152778        1.939583   \n",
       "2     2.761806          99.475694         14.163194        3.524306   \n",
       "3     5.974306          70.609722         72.734028        4.377083   \n",
       "4     1.670139          39.194444         68.250000        3.075000   \n",
       "\n",
       "   Wind_direction_max  Rainfall  \n",
       "0                 NaN       7.2  \n",
       "1               144.0       2.4  \n",
       "2                 NaN       5.8  \n",
       "3                 NaN       0.0  \n",
       "4               213.0       0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"NNdata.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be able to save images on server\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "\n",
    "\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "\n",
    "\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "\n",
    "\n",
    "def invert_scale(scaler, X, yhat):\n",
    "\tnew_row = [x for x in X] + [yhat]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# evaluate the model on a dataset, returns RMSE in transformed units\n",
    "\n",
    "\n",
    "def evaluate(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n",
    "\t# separate\n",
    "\tX, y = scaled_dataset[:, 0:-1], scaled_dataset[:, -1]\n",
    "\t# reshape\n",
    "\treshaped = X.reshape(len(X), 1, 1)\n",
    "\t# forecast dataset\n",
    "\toutput = model.predict(reshaped, batch_size=batch_size)\n",
    "\t# invert data transforms on forecast\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(output)):\n",
    "\t\tyhat = output[i, 0]\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X[i], yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = yhat + raw_data[i]\n",
    "\t\t# store forecast\n",
    "\t\tpredictions.append(yhat)\n",
    "\t# report performance\n",
    "\trmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n",
    "\t# reset model state\n",
    "\tmodel.reset_states()\n",
    "\treturn rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, test, raw, scaler, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\t# prepare model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(\n",
    "\t\tbatch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t# fit model\n",
    "\ttrain_rmse, test_rmse = list(), list()\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\t\t# evaluate model on train data\n",
    "\t\traw_train = raw[-(len(train)+len(test)+1):-len(test)]\n",
    "\t\ttrain_rmse.append(evaluate(model, raw_train, train, scaler, 0, batch_size))\n",
    "\t\t# evaluate model on test data\n",
    "\t\traw_test = raw[-(len(test)+1):]\n",
    "\t\ttest_rmse.append(evaluate(model, raw_test, test, scaler, 0, batch_size))\n",
    "\thistory = DataFrame()\n",
    "\thistory['train'], history['test'] = train_rmse, test_rmse\n",
    "\treturn history\n",
    "\n",
    "# run diagnostic experiments\n",
    "\n",
    "\n",
    "def run():\n",
    "\t# config\n",
    "\tn_lag = 1\n",
    "\tn_repeats = 10\n",
    "\tn_epochs = 1000\n",
    "\tn_batch = 4\n",
    "\tn_neurons = 3\n",
    "\t# load dataset\n",
    "\tseries = read_csv('shampoo-sales.csv', header=0,\n",
    "\t                  parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, n_lag)\n",
    "\tsupervised_values = supervised.values[n_lag:, :]\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# fit and evaluate model\n",
    "\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t# run diagnostic tests\n",
    "\tfor i in range(n_repeats):\n",
    "\t\thistory = fit_lstm(train_trimmed, test_scaled, raw_values,\n",
    "\t\t                   scaler, n_batch, n_epochs, n_neurons)\n",
    "\t\tpyplot.plot(history['train'], color='blue')\n",
    "\t\tpyplot.plot(history['test'], color='orange')\n",
    "\t\tprint('%d) TrainRMSE=%f, TestRMSE=%f' %\n",
    "\t\t      (i+1, history['train'].iloc[-1], history['test'].iloc[-1]))\n",
    "\tpyplot.savefig('diagnostic_baseline.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:34:04.352105: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-20 21:34:04.352862: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:34:04.752683: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-20 21:34:04.755127: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-20 21:34:05.095220: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 21:34:05.150043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d107ec7e4cc286d04dd197e44863c8f859f25f04295a73ad253f41fad7b0dc0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
